{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a8ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4c93f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVe.\n",
      "Go.\tVete.\n",
      "Go.\tVaya.\n",
      "Go.\tVáyase.\n",
      "Hi.\tHola.\n",
      "Run!\t¡Corre!\n",
      "Run.\tCorred.\n",
      "Who?\t¿Quién?\n",
      "Wow!\t¡Órale!\n",
      "Fire!\t¡Fuego!\n",
      "Fire!\t¡Incendio!\n",
      "Fire!\t¡Disparad!\n",
      "Help!\t¡Ayuda!\n",
      "Help!\t¡Socorro! ¡Auxilio!\n",
      "Help!\t¡Auxilio!\n",
      "Jump!\t¡Salta!\n",
      "Jump.\tSalte.\n",
      "Stop!\t¡Parad!\n",
      "Stop!\t¡Para!\n",
      "Stop!\t¡Pare!\n",
      "Wait!\t¡Espera!\n",
      "Wait.\tEsperen.\n",
      "Go on.\tContinúa.\n",
      "Go on.\tContinúe.\n",
      "Hello!\tHola.\n",
      "I ran.\tCorrí.\n",
      "I ran.\tCorría.\n",
      "I try.\tLo intento.\n",
      "I won!\t¡He ganado!\n",
      "Oh no!\t¡Oh, no!\n",
      "Relax.\tTomátelo con soda.\n",
      "Smile.\tSonríe.\n",
      "Attack!\t¡Al ataque!\n",
      "Attack!\t¡Atacad!\n",
      "Get up.\tLevanta.\n",
      "Go now.\tVe ahora mismo.\n",
      "Got it!\t¡Lo tengo!\n",
      "Got it?\t¿Lo pillas?\n",
      "Got it?\t¿Entendiste?\n",
      "He ran.\tÉl corrió.\n",
      "Hop in.\tMétete adentro.\n",
      "Hug me.\tAbrázame.\n",
      "I fell.\tMe caí.\n",
      "I know.\tYo lo sé.\n",
      "I left.\tSalí.\n",
      "I lied.\tMentí.\n",
      "I lost.\tPerdí.\n",
      "I quit.\tDimito.\n",
      "I quit.\tRenuncié.\n",
      "I sang.\tCanté.\n",
      "I work.\tEstoy trabajando.\n",
      "I'm 19.\tTengo diecinueve.\n",
      "I'm up.\tEstoy levantado.\n",
      "Listen.\tEscucha.\n",
      "Listen.\tEscuche.\n",
      "Listen.\tEscuchen.\n",
      "No way!\t¡No puede ser!\n",
      "No way!\tDe ninguna manera.\n",
      "No way!\t¡De ninguna m\n"
     ]
    }
   ],
   "source": [
    "path_to_data = r\"C:\\Users\\Chrispdl\\Desktop\\live speech recognition\\spa.txt\"\n",
    "translation_file = open(path_to_data, \"r\", encoding='utf-8') \n",
    "raw_data = translation_file.read()\n",
    "translation_file.close()\n",
    "print(raw_data[:1000])\n",
    "raw_data = raw_data.split('\\n')\n",
    "pairs = [sentence.split('\\t') for sentence in raw_data]\n",
    "pairs = pairs[1000:20000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87ef6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    # Lower case the sentence\n",
    "    lower_case_sent = sentence.lower()\n",
    "    # Strip punctuation\n",
    "    string_punctuation = string.punctuation + \"¡\" + '¿'\n",
    "    # str.maketrans('', '', string_punctuation) this will work as translation map \n",
    "    clean_sentence = lower_case_sent.translate(str.maketrans('', '', string_punctuation))\n",
    "    return clean_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77d076ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    # Create tokenizer\n",
    "    text_tokenizer = Tokenizer()\n",
    "    # Fit texts\n",
    "    text_tokenizer.fit_on_texts(sentences)\n",
    "    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5067d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length spanish sentence: 12\n",
      "Maximum length english sentence: 6\n",
      "Spanish vocabulary is of 7225 unique words\n",
      "English vocabulary is of 3800 unique words\n"
     ]
    }
   ],
   "source": [
    "# Clean sentences\n",
    "english_sentences = [clean_sentence(pair[0]) for pair in pairs]\n",
    "spanish_sentences = [clean_sentence(pair[1]) for pair in pairs]\n",
    "\n",
    "\n",
    "# Tokenize words\n",
    "spa_text_tokenized, spa_text_tokenizer = tokenize(spanish_sentences)\n",
    "eng_text_tokenized, eng_text_tokenizer = tokenize(english_sentences)\n",
    "\n",
    "print('Maximum length spanish sentence: {}'.format(len(max(spa_text_tokenized,key=len))))\n",
    "print('Maximum length english sentence: {}'.format(len(max(eng_text_tokenized,key=len))))\n",
    "\n",
    "\n",
    "# Check language length\n",
    "spanish_vocab = len(spa_text_tokenizer.word_index) + 1\n",
    "english_vocab = len(eng_text_tokenizer.word_index) + 1\n",
    "print(f\"Spanish vocabulary is of {spanish_vocab} unique words\")\n",
    "print(f\"English vocabulary is of {english_vocab} unique words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40866ba",
   "metadata": {},
   "source": [
    "From the previous code we have a maximum length of 12 words for Spanish sentences and 6 words for English. Here we can see the advantage of using an encoder decoder model. Otherwise you should apply padding to the english sentences up to 12.Consequently with seq2seq model we are reducinf the number of LSTM time steps , reducing computation needs and complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df263195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we apply padding to make the maximum length of the sentences in each lanuage equal \n",
    "\n",
    "max_spanish_len = int(len(max(spa_text_tokenized,key=len)))\n",
    "max_english_len = int(len(max(eng_text_tokenized,key=len)))\n",
    "\n",
    "spa_pad_sentence = pad_sequences(spa_text_tokenized, max_spanish_len, padding = \"post\")\n",
    "eng_pad_sentence = pad_sequences(eng_text_tokenized, max_english_len, padding = \"post\")\n",
    "\n",
    "# Reshape data\n",
    "spa_pad_sentence = spa_pad_sentence.reshape(*spa_pad_sentence.shape, 1)\n",
    "eng_pad_sentence = eng_pad_sentence.reshape(*eng_pad_sentence.shape, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be30dc2",
   "metadata": {},
   "source": [
    "## ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01ce8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_sequence = Input(shape=(max_spanish_len,))\n",
    "embedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e6294",
   "metadata": {},
   "source": [
    "the ‘input_dim’ which is the length of the Spanish vocabulary and ‘output_dim’ which is the shape of the embedding vector. \n",
    "The higher the output dimension the more semantic meaning you can extract from each word, but also the higher the calculations required and the processing time. Finding a balance between speed and performance is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83c544",
   "metadata": {},
   "source": [
    "Next we will add the LSTM layer of size 64. Even though each time step of the LSTM outputs a hidden vector, we will focus our attention on the last one, therefore the parameter return_sequences is ‘False’. We will see how the LSTM layer works with return_sequences=True for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86effbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LSTM(64, return_sequences=False)(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a165d",
   "metadata": {},
   "source": [
    "The output of the encoder layer will be the hidden state of the last time step. We will then need to feed this vector into the decoder. Let’s look more precisely at the decoder part and understand how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779b2c5",
   "metadata": {},
   "source": [
    "The hidden vector is repeated n times, so each time step of the LSTM receives the same vector. In order to have this same vector for every time step we need to use the layer RepeatVector, as its names implies its role is to repeat the vector it is receiving, the only parameter we need to define is n, the number of repetitions. This number is equal to the number of time step of the decoder part, in other words the maximum English sentence length, 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6de6d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vec = RepeatVector(max_english_len)(encoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daded2a6",
   "metadata": {},
   "source": [
    "## DECODER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e6736",
   "metadata": {},
   "source": [
    "This is also built with a LSTM layer, the difference is the parameter return_sequences, which in this case is ‘True’. What is this parameter for? In the encoder part we were expecting only one vector in the last time step and neglecting all the others, here we are expecting an output vector at every time step so the Dense layer can make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e53b387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2097bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = TimeDistributed(Dense(english_vocab))(decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c10a2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 12)]              0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 12, 128)           924800    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 6, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 6, 64)             33024     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 6, 3800)          247000    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 6, 3800)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,254,232\n",
      "Trainable params: 1,254,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_dec_model = Model(input_sequence, Activation('softmax')(logits))\n",
    "enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
    "              optimizer=Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "enc_dec_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e6fd210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "634/634 [==============================] - 16s 19ms/step - loss: 4.1314 - accuracy: 0.4350\n",
      "Epoch 2/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.5050 - accuracy: 0.4652\n",
      "Epoch 3/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.4305 - accuracy: 0.4658\n",
      "Epoch 4/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.4003 - accuracy: 0.4658\n",
      "Epoch 5/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.3549 - accuracy: 0.4687\n",
      "Epoch 6/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.2482 - accuracy: 0.4742\n",
      "Epoch 7/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.1692 - accuracy: 0.4798\n",
      "Epoch 8/100\n",
      "634/634 [==============================] - 12s 19ms/step - loss: 3.1131 - accuracy: 0.4827\n",
      "Epoch 9/100\n",
      "634/634 [==============================] - 12s 20ms/step - loss: 3.0307 - accuracy: 0.4952\n",
      "Epoch 10/100\n",
      "634/634 [==============================] - 12s 20ms/step - loss: 2.8890 - accuracy: 0.5120\n",
      "Epoch 11/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 2.7671 - accuracy: 0.5248\n",
      "Epoch 12/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 2.6706 - accuracy: 0.5359\n",
      "Epoch 13/100\n",
      "634/634 [==============================] - 12s 20ms/step - loss: 2.5765 - accuracy: 0.5476\n",
      "Epoch 14/100\n",
      "634/634 [==============================] - 12s 20ms/step - loss: 2.4868 - accuracy: 0.5555\n",
      "Epoch 15/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 2.3962 - accuracy: 0.5646\n",
      "Epoch 16/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 2.3064 - accuracy: 0.5748\n",
      "Epoch 17/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 2.2201 - accuracy: 0.5872\n",
      "Epoch 18/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 2.1391 - accuracy: 0.5966\n",
      "Epoch 19/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 2.0599 - accuracy: 0.6069\n",
      "Epoch 20/100\n",
      "634/634 [==============================] - 12s 20ms/step - loss: 1.9856 - accuracy: 0.6170\n",
      "Epoch 21/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.9158 - accuracy: 0.6260\n",
      "Epoch 22/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.8484 - accuracy: 0.6347\n",
      "Epoch 23/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.7865 - accuracy: 0.6432\n",
      "Epoch 24/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.7279 - accuracy: 0.6509\n",
      "Epoch 25/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.6717 - accuracy: 0.6575\n",
      "Epoch 26/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.6164 - accuracy: 0.6658\n",
      "Epoch 27/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.5699 - accuracy: 0.6715\n",
      "Epoch 28/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.5191 - accuracy: 0.6787\n",
      "Epoch 29/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.4714 - accuracy: 0.6859\n",
      "Epoch 30/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.4285 - accuracy: 0.6917\n",
      "Epoch 31/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.3830 - accuracy: 0.6985\n",
      "Epoch 32/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.3398 - accuracy: 0.7056\n",
      "Epoch 33/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.2994 - accuracy: 0.7116\n",
      "Epoch 34/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.2607 - accuracy: 0.7174\n",
      "Epoch 35/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.2202 - accuracy: 0.7249\n",
      "Epoch 36/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.1818 - accuracy: 0.7318\n",
      "Epoch 37/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.1481 - accuracy: 0.7365\n",
      "Epoch 38/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.1125 - accuracy: 0.7442\n",
      "Epoch 39/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.0755 - accuracy: 0.7507\n",
      "Epoch 40/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.0445 - accuracy: 0.7562\n",
      "Epoch 41/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 1.0152 - accuracy: 0.7616\n",
      "Epoch 42/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.9844 - accuracy: 0.7681\n",
      "Epoch 43/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.9527 - accuracy: 0.7733\n",
      "Epoch 44/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.9270 - accuracy: 0.7802\n",
      "Epoch 45/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.9022 - accuracy: 0.7847\n",
      "Epoch 46/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.8726 - accuracy: 0.7907\n",
      "Epoch 47/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.8502 - accuracy: 0.7945\n",
      "Epoch 48/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.8218 - accuracy: 0.8017\n",
      "Epoch 49/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.8034 - accuracy: 0.8057\n",
      "Epoch 50/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.7803 - accuracy: 0.8108\n",
      "Epoch 51/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.7606 - accuracy: 0.8155\n",
      "Epoch 52/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.7409 - accuracy: 0.8191\n",
      "Epoch 53/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.7243 - accuracy: 0.8220\n",
      "Epoch 54/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.7007 - accuracy: 0.8284\n",
      "Epoch 55/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.6846 - accuracy: 0.8316\n",
      "Epoch 56/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.6658 - accuracy: 0.8346\n",
      "Epoch 57/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.6545 - accuracy: 0.8377\n",
      "Epoch 58/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.6378 - accuracy: 0.8424\n",
      "Epoch 59/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.6229 - accuracy: 0.8457\n",
      "Epoch 60/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.6081 - accuracy: 0.8476\n",
      "Epoch 61/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5969 - accuracy: 0.8505\n",
      "Epoch 62/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5806 - accuracy: 0.8544\n",
      "Epoch 63/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5691 - accuracy: 0.8554\n",
      "Epoch 64/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5564 - accuracy: 0.8581\n",
      "Epoch 65/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5433 - accuracy: 0.8620\n",
      "Epoch 66/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5357 - accuracy: 0.8638\n",
      "Epoch 67/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5257 - accuracy: 0.8658\n",
      "Epoch 68/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5129 - accuracy: 0.8674\n",
      "Epoch 69/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.5046 - accuracy: 0.8703\n",
      "Epoch 70/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.4896 - accuracy: 0.8741\n",
      "Epoch 71/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.4837 - accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4782 - accuracy: 0.8758\n",
      "Epoch 73/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4636 - accuracy: 0.8791\n",
      "Epoch 74/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4578 - accuracy: 0.8808\n",
      "Epoch 75/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.4524 - accuracy: 0.8816\n",
      "Epoch 76/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4426 - accuracy: 0.8832\n",
      "Epoch 77/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4336 - accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4274 - accuracy: 0.8872\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/634 [==============================] - 13s 20ms/step - loss: 0.4188 - accuracy: 0.8898\n",
      "Epoch 80/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.4121 - accuracy: 0.8910\n",
      "Epoch 81/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.4068 - accuracy: 0.8915\n",
      "Epoch 82/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3985 - accuracy: 0.8922\n",
      "Epoch 83/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3947 - accuracy: 0.8942\n",
      "Epoch 84/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3874 - accuracy: 0.8961\n",
      "Epoch 85/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3836 - accuracy: 0.8960\n",
      "Epoch 86/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3744 - accuracy: 0.8984\n",
      "Epoch 87/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3682 - accuracy: 0.9004\n",
      "Epoch 88/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3688 - accuracy: 0.8983\n",
      "Epoch 89/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3637 - accuracy: 0.9007\n",
      "Epoch 90/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3570 - accuracy: 0.9010\n",
      "Epoch 91/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3525 - accuracy: 0.9034\n",
      "Epoch 92/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3436 - accuracy: 0.9056\n",
      "Epoch 93/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3420 - accuracy: 0.9062\n",
      "Epoch 94/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3393 - accuracy: 0.9064\n",
      "Epoch 95/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3320 - accuracy: 0.9071\n",
      "Epoch 96/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3274 - accuracy: 0.9080\n",
      "Epoch 97/100\n",
      "634/634 [==============================] - 13s 20ms/step - loss: 0.3261 - accuracy: 0.9086\n",
      "Epoch 98/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3209 - accuracy: 0.9094\n",
      "Epoch 99/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3175 - accuracy: 0.9106\n",
      "Epoch 100/100\n",
      "634/634 [==============================] - 13s 21ms/step - loss: 0.3143 - accuracy: 0.9116\n"
     ]
    }
   ],
   "source": [
    "model_results = enc_dec_model.fit(spa_pad_sentence, eng_pad_sentence, batch_size=30, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ab6e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The english sentence is: hes broke\n",
      "The spanish sentence is: está sin blanca\n",
      "The predicted sentence is :\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "hes broke    \n"
     ]
    }
   ],
   "source": [
    "def logits_to_sentence(logits, tokenizer):\n",
    "    # Create a mapping from index to word using the tokenizer's word_index\n",
    "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
    "    # Filter out <empty> tokens\n",
    "    index_to_words = {idx: word for idx, word in index_to_words.items() if word != '<empty>'}\n",
    "    # Convert the predicted logits to a human-readable sentence\n",
    "    return ' '.join([index_to_words.get(prediction, \"\") for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "\n",
    "index = 20\n",
    "print(\"The english sentence is: {}\".format(english_sentences[index]))\n",
    "print(\"The spanish sentence is: {}\".format(spanish_sentences[index]))\n",
    "print('The predicted sentence is :')\n",
    "print(logits_to_sentence(enc_dec_model.predict(spa_pad_sentence[index:index+1])[0], eng_text_tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38d2aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "path_to_save_model = r\"C:\\Users\\Chrispdl\\Desktop\\live speech recognition\\model.h5\"\n",
    "enc_dec_model.save(path_to_save_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74d64a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Original Sentence (Spanish): Mañana vamos a explorar la ciudad\n",
      "Predicted Sentence (English): come home    \n"
     ]
    }
   ],
   "source": [
    "# Input a real sentence in Spanish\n",
    "input_sentence = \"Mañana vamos a explorar la ciudad\"  # Replace with your own Spanish sentence\n",
    "\n",
    "# Tokenize and pad the input sentence\n",
    "input_sequence = spa_text_tokenizer.texts_to_sequences([input_sentence])\n",
    "input_pad_sequence = pad_sequences(input_sequence, max_spanish_len, padding=\"post\")\n",
    "\n",
    "# Use the model to predict the translation\n",
    "predicted_logits = enc_dec_model.predict(input_pad_sequence)[0]\n",
    "\n",
    "# Print the original and predicted sentences\n",
    "print(\"Original Sentence (Spanish):\", input_sentence)\n",
    "print(\"Predicted Sentence (English):\", logits_to_sentence(predicted_logits, eng_text_tokenizer))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
